// src/lib/getJSONSchemaDefaults.ts
import traverse from "json-schema-traverse";
function getJSONSchemaDefaults(jsonSchemas) {
  return jsonSchemas.map(({ type: payloadType, schema: jsonSchema }) => {
    const defaults = {};
    traverse(
      jsonSchema,
      (schema, pointer, rootSchema, parentPointer, parentKeyword, parentSchema, indexProperty) => {
        if (!pointer.startsWith("/properties/")) {
          return;
        }
        if (Array.isArray(parentSchema?.required) && parentSchema?.required.includes(String(indexProperty))) {
          if (schema.type === "object" && indexProperty) {
            defaults[indexProperty] = {};
          }
          let destination = defaults;
          if (parentPointer) {
            parentPointer.replace(/\/properties/g, "").split("/").forEach((subSchema) => {
              if (subSchema === "") {
                return;
              }
              destination = destination?.[subSchema] || {};
            });
          }
          if (schema.default !== void 0) {
            if (indexProperty !== void 0) {
              destination[indexProperty] = schema.default;
            }
          }
        }
      }
    );
    if (!Object.keys(defaults).length) {
      return {};
    }
    return {
      // @todo should we filter out empty and undefined objects from here with `remove-undefined-objects`?
      [payloadType]: defaults
    };
  }).reduce((prev, next) => Object.assign(prev, next));
}

// src/lib/parseResponse.ts
import { matchesMimeType } from "oas/utils";
async function parseResponse(response) {
  const contentType = response.headers.get("Content-Type");
  const isJSON = contentType && (matchesMimeType.json(contentType) || matchesMimeType.wildcard(contentType));
  const responseBody = await response.text();
  let data = responseBody;
  if (isJSON) {
    try {
      data = JSON.parse(responseBody);
    } catch (e) {
    }
  }
  return {
    data,
    status: response.status,
    headers: response.headers,
    res: response
  };
}

// src/lib/prepareAuth.ts
function prepareAuth(authKey, operation) {
  if (authKey.length === 0) {
    return {};
  }
  const preparedAuth = {};
  const security = operation.getSecurity();
  if (security.length === 0) {
    return {};
  }
  if (security.every((s) => Object.keys(s).length > 1)) {
    throw new Error(
      "Sorry, this operation currently requires multiple forms of authentication which this library doesn't yet support."
    );
  }
  const usableSecurity = security.map((s) => {
    return Object.keys(s).length === 1 ? s : false;
  }).filter(Boolean);
  const usableSecuritySchemes = usableSecurity.map((s) => Object.keys(s)).reduce((prev, next) => prev.concat(next), []);
  const preparedSecurity = operation.prepareSecurity();
  if (authKey.length >= 2) {
    if (!("Basic" in preparedSecurity)) {
      throw new Error("Multiple auth tokens were supplied for this endpoint but only a single token is needed.");
    }
    const schemes2 = preparedSecurity.Basic.filter((s) => usableSecuritySchemes.includes(s._key));
    if (!schemes2.length) {
      throw new Error(
        "Credentials for Basic Authentication were supplied but this operation requires another form of auth in that case, which this library does not yet support. This operation does, however, allow supplying a single auth token."
      );
    }
    const scheme2 = schemes2.shift();
    preparedAuth[scheme2._key] = {
      user: String(authKey[0]),
      pass: authKey.length === 2 ? String(authKey[1]) : ""
    };
    return preparedAuth;
  }
  const usableScheme = usableSecuritySchemes[0];
  const schemes = Object.entries(preparedSecurity).map(([, ps]) => ps.filter((s) => usableScheme === s._key)).reduce((prev, next) => prev.concat(next), []);
  const scheme = schemes.shift();
  switch (scheme.type) {
    case "http":
      if (scheme.scheme === "basic") {
        preparedAuth[scheme._key] = {
          user: String(authKey[0]),
          pass: authKey.length === 2 ? String(authKey[1]) : ""
        };
      } else if (scheme.scheme === "bearer") {
        preparedAuth[scheme._key] = authKey[0];
      }
      break;
    case "oauth2":
      preparedAuth[scheme._key] = authKey[0];
      break;
    case "apiKey":
      if (scheme.in === "query" || scheme.in === "header" || scheme.in === "cookie") {
        preparedAuth[scheme._key] = authKey[0];
      }
      break;
    default:
      throw new Error(
        `Sorry, this API currently uses a security scheme, ${scheme.type}, which this library doesn't yet support.`
      );
  }
  return preparedAuth;
}

// src/lib/prepareParams.ts
import fs from "fs";
import path from "path";
import stream from "stream";
import caseless from "caseless";
import DatauriParser from "datauri/parser.js";
import datauri from "datauri/sync.js";

// node_modules/get-stream/source/contents.js
var getStreamContents = async (stream2, { init, convertChunk, getSize, truncateChunk, addChunk, getFinalChunk, finalize }, { maxBuffer = Number.POSITIVE_INFINITY } = {}) => {
  if (!isAsyncIterable(stream2)) {
    throw new Error("The first argument must be a Readable, a ReadableStream, or an async iterable.");
  }
  const state = init();
  state.length = 0;
  try {
    for await (const chunk of stream2) {
      const chunkType = getChunkType(chunk);
      const convertedChunk = convertChunk[chunkType](chunk, state);
      appendChunk({ convertedChunk, state, getSize, truncateChunk, addChunk, maxBuffer });
    }
    appendFinalChunk({ state, convertChunk, getSize, truncateChunk, addChunk, getFinalChunk, maxBuffer });
    return finalize(state);
  } catch (error) {
    error.bufferedData = finalize(state);
    throw error;
  }
};
var appendFinalChunk = ({ state, getSize, truncateChunk, addChunk, getFinalChunk, maxBuffer }) => {
  const convertedChunk = getFinalChunk(state);
  if (convertedChunk !== void 0) {
    appendChunk({ convertedChunk, state, getSize, truncateChunk, addChunk, maxBuffer });
  }
};
var appendChunk = ({ convertedChunk, state, getSize, truncateChunk, addChunk, maxBuffer }) => {
  const chunkSize = getSize(convertedChunk);
  const newLength = state.length + chunkSize;
  if (newLength <= maxBuffer) {
    addNewChunk(convertedChunk, state, addChunk, newLength);
    return;
  }
  const truncatedChunk = truncateChunk(convertedChunk, maxBuffer - state.length);
  if (truncatedChunk !== void 0) {
    addNewChunk(truncatedChunk, state, addChunk, maxBuffer);
  }
  throw new MaxBufferError();
};
var addNewChunk = (convertedChunk, state, addChunk, newLength) => {
  state.contents = addChunk(convertedChunk, state, newLength);
  state.length = newLength;
};
var isAsyncIterable = (stream2) => typeof stream2 === "object" && stream2 !== null && typeof stream2[Symbol.asyncIterator] === "function";
var getChunkType = (chunk) => {
  const typeOfChunk = typeof chunk;
  if (typeOfChunk === "string") {
    return "string";
  }
  if (typeOfChunk !== "object" || chunk === null) {
    return "others";
  }
  if (globalThis.Buffer?.isBuffer(chunk)) {
    return "buffer";
  }
  const prototypeName = objectToString.call(chunk);
  if (prototypeName === "[object ArrayBuffer]") {
    return "arrayBuffer";
  }
  if (prototypeName === "[object DataView]") {
    return "dataView";
  }
  if (Number.isInteger(chunk.byteLength) && Number.isInteger(chunk.byteOffset) && objectToString.call(chunk.buffer) === "[object ArrayBuffer]") {
    return "typedArray";
  }
  return "others";
};
var { toString: objectToString } = Object.prototype;
var MaxBufferError = class extends Error {
  name = "MaxBufferError";
  constructor() {
    super("maxBuffer exceeded");
  }
};

// node_modules/get-stream/source/utils.js
var noop = () => void 0;
var throwObjectStream = (chunk) => {
  throw new Error(`Streams in object mode are not supported: ${String(chunk)}`);
};
var getLengthProp = (convertedChunk) => convertedChunk.length;

// node_modules/get-stream/source/array-buffer.js
async function getStreamAsArrayBuffer(stream2, options) {
  return getStreamContents(stream2, arrayBufferMethods, options);
}
var initArrayBuffer = () => ({ contents: new ArrayBuffer(0) });
var useTextEncoder = (chunk) => textEncoder.encode(chunk);
var textEncoder = new TextEncoder();
var useUint8Array = (chunk) => new Uint8Array(chunk);
var useUint8ArrayWithOffset = (chunk) => new Uint8Array(chunk.buffer, chunk.byteOffset, chunk.byteLength);
var truncateArrayBufferChunk = (convertedChunk, chunkSize) => convertedChunk.slice(0, chunkSize);
var addArrayBufferChunk = (convertedChunk, { contents, length: previousLength }, length) => {
  const newContents = hasArrayBufferResize() ? resizeArrayBuffer(contents, length) : resizeArrayBufferSlow(contents, length);
  new Uint8Array(newContents).set(convertedChunk, previousLength);
  return newContents;
};
var resizeArrayBufferSlow = (contents, length) => {
  if (length <= contents.byteLength) {
    return contents;
  }
  const arrayBuffer = new ArrayBuffer(getNewContentsLength(length));
  new Uint8Array(arrayBuffer).set(new Uint8Array(contents), 0);
  return arrayBuffer;
};
var resizeArrayBuffer = (contents, length) => {
  if (length <= contents.maxByteLength) {
    contents.resize(length);
    return contents;
  }
  const arrayBuffer = new ArrayBuffer(length, { maxByteLength: getNewContentsLength(length) });
  new Uint8Array(arrayBuffer).set(new Uint8Array(contents), 0);
  return arrayBuffer;
};
var getNewContentsLength = (length) => SCALE_FACTOR ** Math.ceil(Math.log(length) / Math.log(SCALE_FACTOR));
var SCALE_FACTOR = 2;
var finalizeArrayBuffer = ({ contents, length }) => hasArrayBufferResize() ? contents : contents.slice(0, length);
var hasArrayBufferResize = () => "resize" in ArrayBuffer.prototype;
var arrayBufferMethods = {
  init: initArrayBuffer,
  convertChunk: {
    string: useTextEncoder,
    buffer: useUint8Array,
    arrayBuffer: useUint8Array,
    dataView: useUint8ArrayWithOffset,
    typedArray: useUint8ArrayWithOffset,
    others: throwObjectStream
  },
  getSize: getLengthProp,
  truncateChunk: truncateArrayBufferChunk,
  addChunk: addArrayBufferChunk,
  getFinalChunk: noop,
  finalize: finalizeArrayBuffer
};

// node_modules/get-stream/source/buffer.js
async function getStreamAsBuffer(stream2, options) {
  if (!("Buffer" in globalThis)) {
    throw new Error("getStreamAsBuffer() is only supported in Node.js");
  }
  try {
    return arrayBufferToNodeBuffer(await getStreamAsArrayBuffer(stream2, options));
  } catch (error) {
    if (error.bufferedData !== void 0) {
      error.bufferedData = arrayBufferToNodeBuffer(error.bufferedData);
    }
    throw error;
  }
}
var arrayBufferToNodeBuffer = (arrayBuffer) => globalThis.Buffer.from(arrayBuffer);

// src/lib/prepareParams.ts
import lodashMerge from "lodash.merge";
import removeUndefinedObjects from "remove-undefined-objects";
var specialHeaders = ["accept", "authorization"];
function digestParameters(parameters) {
  return parameters.reduce((prev, param) => {
    if ("$ref" in param || "allOf" in param || "anyOf" in param || "oneOf" in param) {
      throw new Error("The OpenAPI document for this operation wasn't dereferenced before processing.");
    } else if (param.name in prev) {
      throw new Error(
        `The operation you are using has the same parameter, ${param.name}, spread across multiple entry points. We unfortunately can't handle this right now.`
      );
    }
    return Object.assign(prev, { [param.name]: param });
  }, {});
}
function isEmpty(obj) {
  return [Object, Array].includes((obj || {}).constructor) && !Object.entries(obj || {}).length;
}
function isObject(thing) {
  if (thing instanceof stream.Readable) {
    return false;
  }
  return typeof thing === "object" && thing !== null && !Array.isArray(thing);
}
function isPrimitive(obj) {
  return obj === null || typeof obj === "number" || typeof obj === "string";
}
function merge(src, target) {
  if (Array.isArray(target)) {
    return target;
  } else if (!isObject(target)) {
    return target;
  }
  return lodashMerge(src, target);
}
function processFile(paramName, file) {
  if (typeof file === "string") {
    const resolvedFile = path.resolve(file);
    return new Promise((resolve, reject) => {
      fs.stat(resolvedFile, async (err) => {
        if (err) {
          if (err.code === "ENOENT") {
            return resolve(void 0);
          }
          return reject(err);
        }
        const fileMetadata = await datauri(resolvedFile);
        const payloadFilename = encodeURIComponent(path.basename(resolvedFile));
        return resolve({
          paramName,
          base64: fileMetadata?.content?.replace(";base64", `;name=${payloadFilename};base64`),
          filename: payloadFilename,
          buffer: fileMetadata.buffer
        });
      });
    });
  } else if (file instanceof stream.Readable) {
    return getStreamAsBuffer(file).then((buffer) => {
      const filePath = file.path;
      const parser = new DatauriParser();
      const base64 = parser.format(filePath, buffer).content;
      const payloadFilename = encodeURIComponent(path.basename(filePath));
      return {
        paramName,
        base64: base64?.replace(";base64", `;name=${payloadFilename};base64`),
        filename: payloadFilename,
        buffer
      };
    });
  }
  return Promise.reject(
    new TypeError(
      paramName ? `The data supplied for the \`${paramName}\` request body parameter is not a file handler that we support.` : "The data supplied for the request body payload is not a file handler that we support."
    )
  );
}
async function prepareParams(operation, body, metadata) {
  let metadataIntersected = false;
  const digestedParameters = digestParameters(operation.getParameters());
  const jsonSchema = operation.getParametersAsJSONSchema();
  metadata = removeUndefinedObjects(metadata);
  if (!jsonSchema && (body !== void 0 || metadata !== void 0)) {
    let throwNoParamsError = true;
    if (body !== void 0) {
      if (typeof body === "object" && body !== null && !Array.isArray(body)) {
        if (Object.keys(body).length <= 2) {
          const bodyParams = caseless(body);
          if (specialHeaders.some((header) => bodyParams.has(header))) {
            throwNoParamsError = false;
          }
        }
      }
    }
    if (throwNoParamsError) {
      throw new Error(
        "You supplied metadata and/or body data for this operation but it doesn't have any documented parameters or request payloads. If you think this is an error please contact support for the API you're using."
      );
    }
  }
  const jsonSchemaDefaults = jsonSchema ? getJSONSchemaDefaults(jsonSchema) : {};
  const params = jsonSchemaDefaults;
  if (typeof body !== "undefined") {
    if (Array.isArray(body) || isPrimitive(body)) {
      params.body = merge(params.body, body);
    } else if (typeof metadata === "undefined") {
      const headerParams = caseless({});
      Object.entries(digestedParameters).forEach(([paramName, param]) => {
        if (param.in === "header") {
          headerParams.set(paramName, "");
        }
      });
      specialHeaders.forEach((header) => {
        if (!headerParams.has(header)) {
          headerParams.set(header, "");
        }
      });
      const intersection = Object.keys(body).filter((value) => {
        if (Object.keys(digestedParameters).includes(value)) {
          return true;
        } else if (headerParams.has(value)) {
          return true;
        }
        return false;
      }).length;
      if (intersection && intersection / Object.keys(body).length > 0.25) {
        metadataIntersected = true;
        metadata = merge(params.body, body);
        body = void 0;
      } else {
        params.body = merge(params.body, body);
      }
    } else {
      params.body = merge(params.body, body);
    }
  }
  if (!operation.hasRequestBody()) {
    delete params.body;
  } else {
    if (!("body" in params))
      params.body = {};
    const payloadJsonSchema = jsonSchema.find((js) => js.type === "body");
    if (payloadJsonSchema) {
      if (!params.files)
        params.files = {};
      const conversions = [];
      if (payloadJsonSchema.schema?.properties) {
        Object.entries(payloadJsonSchema.schema?.properties).filter(([, schema]) => schema?.format === "binary").filter(([prop]) => Object.keys(params.body).includes(prop)).forEach(([prop]) => {
          conversions.push(processFile(prop, params.body[prop]));
        });
      } else if (payloadJsonSchema.schema?.type === "string") {
        if (payloadJsonSchema.schema?.format === "binary") {
          conversions.push(processFile(void 0, params.body));
        }
      }
      await Promise.all(conversions).then((fileMetadata) => fileMetadata.filter(Boolean)).then((fm) => {
        fm.forEach((fileMetadata) => {
          if (!fileMetadata) {
            return;
          }
          if (fileMetadata.paramName) {
            params.body[fileMetadata.paramName] = fileMetadata.base64;
          } else {
            params.body = fileMetadata.base64;
          }
          if (fileMetadata.buffer && params?.files) {
            params.files[fileMetadata.filename] = fileMetadata.buffer;
          }
        });
      });
    }
  }
  if (operation.isFormUrlEncoded()) {
    params.formData = merge(params.formData, params.body);
    delete params.body;
  }
  if (typeof metadata !== "undefined") {
    if (!("cookie" in params))
      params.cookie = {};
    if (!("header" in params))
      params.header = {};
    if (!("path" in params))
      params.path = {};
    if (!("query" in params))
      params.query = {};
    Object.entries(digestedParameters).forEach(([paramName, param]) => {
      let value;
      let metadataHeaderParam;
      if (typeof metadata === "object" && !isEmpty(metadata)) {
        if (paramName in metadata) {
          value = metadata[paramName];
          metadataHeaderParam = paramName;
        } else if (param.in === "header") {
          metadataHeaderParam = Object.keys(metadata).find((k) => k.toLowerCase() === paramName.toLowerCase()) || "";
          value = metadata[metadataHeaderParam];
        }
      }
      if (value === void 0) {
        return;
      }
      switch (param.in) {
        case "path":
          params.path[paramName] = value;
          if (metadata?.[paramName])
            delete metadata[paramName];
          break;
        case "query":
          params.query[paramName] = value;
          if (metadata?.[paramName])
            delete metadata[paramName];
          break;
        case "header":
          params.header[paramName.toLowerCase()] = value;
          if (metadataHeaderParam && metadata?.[metadataHeaderParam])
            delete metadata[metadataHeaderParam];
          break;
        case "cookie":
          params.cookie[paramName] = value;
          if (metadata?.[paramName])
            delete metadata[paramName];
          break;
        default:
      }
      if (metadataIntersected && operation.isFormUrlEncoded()) {
        if (paramName in params.formData) {
          delete params.formData[paramName];
        }
      }
    });
    if (!isEmpty(metadata)) {
      if (typeof metadata === "object") {
        specialHeaders.forEach((headerName) => {
          const headerParam = Object.keys(metadata || {}).find((m) => m.toLowerCase() === headerName);
          if (headerParam) {
            if (typeof metadata === "object") {
              if (typeof params.header === "object") {
                params.header[headerName] = metadata[headerParam];
              }
              delete metadata[headerParam];
            }
          }
        });
      }
      if (operation.isFormUrlEncoded()) {
        params.formData = merge(params.formData, metadata);
      } else {
      }
    }
  }
  ["body", "cookie", "files", "formData", "header", "path", "query"].forEach((type) => {
    if (type in params && isEmpty(params[type])) {
      delete params[type];
    }
  });
  return params;
}

// src/lib/prepareServer.ts
function stripTrailingSlash(url) {
  if (url[url.length - 1] === "/") {
    return url.slice(0, -1);
  }
  return url;
}
function prepareServer(spec, url, variables = {}) {
  let serverIdx;
  const sanitizedUrl = stripTrailingSlash(url);
  (spec.api.servers || []).forEach((server, i) => {
    if (server.url === sanitizedUrl) {
      serverIdx = i;
    }
  });
  if (serverIdx) {
    return {
      selected: serverIdx,
      variables
    };
  } else if (Object.keys(variables).length) {
  } else {
    const server = spec.splitVariables(url);
    if (server) {
      return {
        selected: server.selected,
        variables: server.variables
      };
    }
  }
  return false;
}

export {
  getJSONSchemaDefaults,
  parseResponse,
  prepareAuth,
  prepareParams,
  prepareServer
};
//# sourceMappingURL=chunk-KZ6XNAIH.js.map